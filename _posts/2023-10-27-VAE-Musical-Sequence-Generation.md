---
title: "Musical Sequence Generation in Eurorack Using a Variational Autoencoder"
published: false
---
# Musical Sequence Generation in Eurorack Using a Variational Autoencoder

## Variation Autoencoder Architecture

A variational autoencoder (VAE) to a type of neural network. A VAE learns to encode complex data into a lower-dimensional space (latent space) and then decode it back to the original data space. New data can then be generated by sampling from the latent space.

The input of the encoder is a fixed length sequence of boolean values which represet a fixed length sequence of musical notes. e.g. If notes are represented by points on a grid with pitch vertically and time horizontally, the input to the VAE is a flattened version of this.

![Input](/assets/images/2023-10-27-vae-musical-sequence-generation/input_encoding.drawio.png)

The VAE has an input for each note per tick of the clock, so the total number of inputs is notes x ticks.

Training is done by presenting the same input data as output data. The bottleneck in the VAE causes it to find a low dimensional representation of the input. In this case 3 numbers are all that are needed to represent a particular piece of input data.

![VAE](/assets/images/2023-10-27-vae-musical-sequence-generation/vae_training.drawio.png)

One the VAE is trained the decoder part of the network is converted to tflite which is aformat that we can use on hardware. The latent variables can be set directly from a potentiomer or control voltage input to generate a new sequence.

![Decoder](/assets/images/2023-10-27-vae-musical-sequence-generation/vae_inference.drawio.png)

The output sequence is then converted back into a time based sequence by spliting it up and fed to the outputs based on an external clock pulse.

## Training

TOOD gathering midi data

TODO converting midi to training format

## Inference

TODO link to code to perform inference to test model

## Drum Mapping


